{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1669775157942
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import os\n",
        "import copy\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "from models import SRCNN\n",
        "from datasets import TrainDataset, EvalDataset\n",
        "from utils import AverageMeter, calc_psnr\n",
        "\n",
        "import mlflow\n",
        "import numpy as np\n",
        "from azureml.core import Workspace\n",
        "from mlflow import MlflowClient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1669774683046
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "ws = Workspace.from_config()\n",
        "experiment_name = \"isr_cs5412\"\n",
        "\n",
        "# set up MLflow to track the metrics\n",
        "mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\n",
        "mlflow.set_experiment(experiment_name)\n",
        "mlflow.autolog()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1669775161436
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "train_file = \"data/91-image_x4.h5\"\n",
        "eval_file = \"data/Set5_x4.h5\"\n",
        "outputs_dir = \"outputs\"\n",
        "scale = 3\n",
        "lr = 1e-4\n",
        "B = 16\n",
        "E = 150\n",
        "n_workers = 8\n",
        "seed = 114\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1669758828976
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "epoch: 0/149:   0%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | 0/21760 [00:04<?, ?it/s]\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "cuDNN error: CUDNN_STATUS_INTERNAL_ERROR\nYou can try to repro this exception using the following code snippet. If that doesn't trigger the error, please include your original repro script when reporting this issue.\n\nimport torch\ntorch.backends.cuda.matmul.allow_tf32 = False\ntorch.backends.cudnn.benchmark = True\ntorch.backends.cudnn.deterministic = False\ntorch.backends.cudnn.allow_tf32 = True\ndata = torch.randn([16, 1, 33, 33], dtype=torch.float, device='cuda', requires_grad=True)\nnet = torch.nn.Conv2d(1, 64, kernel_size=[9, 9], padding=[4, 4], stride=[1, 1], dilation=[1, 1], groups=1)\nnet = net.cuda().float()\nout = net(data)\nout.backward(torch.randn_like(out))\ntorch.cuda.synchronize()\n\nConvolutionParams \n    memory_format = Contiguous\n    data_type = CUDNN_DATA_FLOAT\n    padding = [4, 4, 0]\n    stride = [1, 1, 0]\n    dilation = [1, 1, 0]\n    groups = 1\n    deterministic = false\n    allow_tf32 = true\ninput: TensorDescriptor 0x559502cd91f0\n    type = CUDNN_DATA_FLOAT\n    nbDims = 4\n    dimA = 16, 1, 33, 33, \n    strideA = 1089, 1089, 33, 1, \noutput: TensorDescriptor 0x5595025fbdd0\n    type = CUDNN_DATA_FLOAT\n    nbDims = 4\n    dimA = 16, 64, 33, 33, \n    strideA = 69696, 1089, 33, 1, \nweight: FilterDescriptor 0x55950316b6b0\n    type = CUDNN_DATA_FLOAT\n    tensor_format = CUDNN_TENSOR_NCHW\n    nbDims = 4\n    dimA = 64, 1, 9, 9, \nPointer addresses: \n    input: 0x1101050c00\n    output: 0x11011e0000\n    weight: 0x1100fe0000\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m/home/azureuser/cloudfiles/code/Users/ty373/srcnn-pytorch/isr.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 47>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f31396164656363652d356536352d343331352d383235352d6131336232316435663533662f7265736f7572636547726f7570732f4353353431322d7a773537372d74793337332f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f4353353431322d7a773537372d74793337332f636f6d70757465732f747933373332/home/azureuser/cloudfiles/code/Users/ty373/srcnn-pytorch/isr.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f31396164656363652d356536352d343331352d383235352d6131336232316435663533662f7265736f7572636547726f7570732f4353353431322d7a773537372d74793337332f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f4353353431322d7a773537372d74793337332f636f6d70757465732f747933373332/home/azureuser/cloudfiles/code/Users/ty373/srcnn-pytorch/isr.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f31396164656363652d356536352d343331352d383235352d6131336232316435663533662f7265736f7572636547726f7570732f4353353431322d7a773537372d74793337332f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f4353353431322d7a773537372d74793337332f636f6d70757465732f747933373332/home/azureuser/cloudfiles/code/Users/ty373/srcnn-pytorch/isr.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m preds \u001b[39m=\u001b[39m model(inputs)\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f31396164656363652d356536352d343331352d383235352d6131336232316435663533662f7265736f7572636547726f7570732f4353353431322d7a773537372d74793337332f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f4353353431322d7a773537372d74793337332f636f6d70757465732f747933373332/home/azureuser/cloudfiles/code/Users/ty373/srcnn-pytorch/isr.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(preds, labels)\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f31396164656363652d356536352d343331352d383235352d6131336232316435663533662f7265736f7572636547726f7570732f4353353431322d7a773537372d74793337332f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f4353353431322d7a773537372d74793337332f636f6d70757465732f747933373332/home/azureuser/cloudfiles/code/Users/ty373/srcnn-pytorch/isr.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=63'>64</a>\u001b[0m epoch_losses\u001b[39m.\u001b[39mupdate(loss\u001b[39m.\u001b[39mitem(), \u001b[39mlen\u001b[39m(inputs))\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/ty3732/code/Users/ty373/srcnn-pytorch/models.py:13\u001b[0m, in \u001b[0;36mSRCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 13\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x))\n\u001b[1;32m     14\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x))\n\u001b[1;32m     15\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv3(x)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torch/nn/modules/conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 457\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torch/nn/modules/conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    450\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    451\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    452\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 453\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    454\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR\nYou can try to repro this exception using the following code snippet. If that doesn't trigger the error, please include your original repro script when reporting this issue.\n\nimport torch\ntorch.backends.cuda.matmul.allow_tf32 = False\ntorch.backends.cudnn.benchmark = True\ntorch.backends.cudnn.deterministic = False\ntorch.backends.cudnn.allow_tf32 = True\ndata = torch.randn([16, 1, 33, 33], dtype=torch.float, device='cuda', requires_grad=True)\nnet = torch.nn.Conv2d(1, 64, kernel_size=[9, 9], padding=[4, 4], stride=[1, 1], dilation=[1, 1], groups=1)\nnet = net.cuda().float()\nout = net(data)\nout.backward(torch.randn_like(out))\ntorch.cuda.synchronize()\n\nConvolutionParams \n    memory_format = Contiguous\n    data_type = CUDNN_DATA_FLOAT\n    padding = [4, 4, 0]\n    stride = [1, 1, 0]\n    dilation = [1, 1, 0]\n    groups = 1\n    deterministic = false\n    allow_tf32 = true\ninput: TensorDescriptor 0x559502cd91f0\n    type = CUDNN_DATA_FLOAT\n    nbDims = 4\n    dimA = 16, 1, 33, 33, \n    strideA = 1089, 1089, 33, 1, \noutput: TensorDescriptor 0x5595025fbdd0\n    type = CUDNN_DATA_FLOAT\n    nbDims = 4\n    dimA = 16, 64, 33, 33, \n    strideA = 69696, 1089, 33, 1, \nweight: FilterDescriptor 0x55950316b6b0\n    type = CUDNN_DATA_FLOAT\n    tensor_format = CUDNN_TENSOR_NCHW\n    nbDims = 4\n    dimA = 64, 1, 9, 9, \nPointer addresses: \n    input: 0x1101050c00\n    output: 0x11011e0000\n    weight: 0x1100fe0000\n"
          ]
        }
      ],
      "source": [
        "# if __name__ == '__main__':\n",
        "#     parser = argparse.ArgumentParser()\n",
        "#     parser.add_argument('--train-file',     default=\"data/91-image_x4.h5\",  type=str)\n",
        "#     parser.add_argument('--eval-file',      default=\"data/Set5_x4.h5\",      type=str)\n",
        "#     parser.add_argument('--outputs-dir',    default=\"outputs\",              type=str)\n",
        "#     parser.add_argument('--scale',          default=3,                      type=int)\n",
        "#     parser.add_argument('--lr',             default=1e-4,                   type=float)\n",
        "#     parser.add_argument('--batch-size',     default=16,                     type=int)\n",
        "#     parser.add_argument('--num-epochs',     default=400,                    type=int)\n",
        "#     parser.add_argument('--num-workers',    default=8,                      type=int)\n",
        "#     parser.add_argument('--seed',           default=114,                    type=int)\n",
        "#     args = parser.parse_args()\n",
        "\n",
        "outputs_dir = os.path.join(outputs_dir, 'x{}'.format(scale))\n",
        "\n",
        "if not os.path.exists(outputs_dir):\n",
        "    os.makedirs(outputs_dir)\n",
        "\n",
        "cudnn.benchmark = True\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "model = SRCNN().to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam([\n",
        "    {'params': model.conv1.parameters()},\n",
        "    {'params': model.conv2.parameters()},\n",
        "    {'params': model.conv3.parameters(), 'lr': lr * 0.1}\n",
        "], lr=lr)\n",
        "\n",
        "train_dataset = TrainDataset(train_file)\n",
        "train_dataloader = DataLoader(dataset=train_dataset,\n",
        "                                batch_size=B,\n",
        "                                shuffle=True,\n",
        "                                num_workers=n_workers,\n",
        "                                pin_memory=True,\n",
        "                                drop_last=True)\n",
        "eval_dataset = EvalDataset(eval_file)\n",
        "eval_dataloader = DataLoader(dataset=eval_dataset, batch_size=1)\n",
        "\n",
        "\n",
        "best_weights = copy.deepcopy(model.state_dict())\n",
        "best_epoch = 0\n",
        "best_psnr = 0.0\n",
        "\n",
        "for epoch in range(E):\n",
        "    model.train()\n",
        "    epoch_losses = AverageMeter()\n",
        "\n",
        "    with tqdm(total=(len(train_dataset) - len(train_dataset) % B)) as t:\n",
        "        t.set_description('epoch: {}/{}'.format(epoch, E - 1))\n",
        "\n",
        "        for data in train_dataloader:\n",
        "            inputs, labels = data\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            preds = model(inputs)\n",
        "\n",
        "            loss = criterion(preds, labels)\n",
        "\n",
        "            epoch_losses.update(loss.item(), len(inputs))\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            t.set_postfix(loss='{:.6f}'.format(epoch_losses.avg))\n",
        "            t.update(len(inputs))\n",
        "\n",
        "    torch.save(model.state_dict(), os.path.join(outputs_dir, 'epoch_{}.pth'.format(epoch)))\n",
        "\n",
        "    model.eval()\n",
        "    epoch_psnr = AverageMeter()\n",
        "\n",
        "    for data in eval_dataloader:\n",
        "        inputs, labels = data\n",
        "\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            preds = model(inputs).clamp(0.0, 1.0)\n",
        "\n",
        "        epoch_psnr.update(calc_psnr(preds, labels), len(inputs))\n",
        "\n",
        "    print('eval psnr: {:.2f}'.format(epoch_psnr.avg))\n",
        "\n",
        "    if epoch_psnr.avg > best_psnr:\n",
        "        best_epoch = epoch\n",
        "        best_psnr = epoch_psnr.avg\n",
        "        best_weights = copy.deepcopy(model.state_dict())\n",
        "\n",
        "print('best epoch: {}, psnr: {:.2f}'.format(best_epoch, best_psnr))\n",
        "torch.save(best_weights, os.path.join(outputs_dir, 'best.pth'))\n",
        "\n",
        "\n",
        "with mlflow.start_run() as run:\n",
        "    mlflow.pytorch.log_model(model, \"model\")\n",
        "\n",
        "    # convert to scripted model and log the model\n",
        "    scripted_pytorch_model = torch.jit.script(model)\n",
        "    mlflow.pytorch.log_model(scripted_pytorch_model, \"scripted_model\")\n",
        "\n",
        "# Fetch the logged model artifacts\n",
        "print(\"run_id: {}\".format(run.info.run_id))\n",
        "for artifact_path in [\"model/data\", \"scripted_model/data\"]:\n",
        "    artifacts = [f.path for f in MlflowClient().list_artifacts(run.info.run_id,\n",
        "                artifact_path)]\n",
        "    print(\"artifacts: {}\".format(artifacts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'run' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/home/azureuser/cloudfiles/code/Users/ty373/srcnn-pytorch/isr.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f31396164656363652d356536352d343331352d383235352d6131336232316435663533662f7265736f7572636547726f7570732f4353353431322d7a773537372d74793337332f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f4353353431322d7a773537372d74793337332f636f6d70757465732f747933373332/home/azureuser/cloudfiles/code/Users/ty373/srcnn-pytorch/isr.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m run\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mrun_id\n",
            "\u001b[0;31mNameError\u001b[0m: name 'run' is not defined"
          ]
        }
      ],
      "source": [
        "run.info.run_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# register the model\n",
        "model_uri = \"runs:/{}/model\".format(run.info.run_id)\n",
        "model = mlflow.register_model(model_uri, \"isr_srcnn_x4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## deployment configs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# create environment for the deploy\n",
        "from azureml.core.environment import Environment\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "from azureml.core.webservice import AciWebservice\n",
        "\n",
        "# get a curated environment\n",
        "env = Environment.get(\n",
        "    workspace=ws, \n",
        "    name=\"AzureML-pytorch-1.12.0-ubuntu18.04-py37-cpu-inference\",\n",
        "    version=1\n",
        ")\n",
        "env.inferencing_stack_version='latest'\n",
        "\n",
        "# create deployment config i.e. compute resources\n",
        "aciconfig = AciWebservice.deploy_configuration(\n",
        "    cpu_cores=8,\n",
        "    memory_gb=32,\n",
        "    tags={\"data\": \"91-images_x4\", \"method\": \"srcnn_isr_x4\"},\n",
        "    description=\"Image Super Resolution with SRCNN\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## deploy model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "import uuid\n",
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.environment import Environment\n",
        "from azureml.core.model import Model\n",
        "\n",
        "# get the registered model\n",
        "model = Model(ws, \"isr_srcnn_x4\")\n",
        "\n",
        "# create an inference config i.e. the scoring script and environment\n",
        "inference_config = InferenceConfig(entry_script=\"model_inference.py\", environment=env)\n",
        "\n",
        "# deploy the service\n",
        "service_name = \"isr-srcnn-x4-\" + str(uuid.uuid4())[:4]\n",
        "service = Model.deploy(\n",
        "    workspace=ws,\n",
        "    name=service_name,\n",
        "    models=[model],\n",
        "    inference_config=inference_config,\n",
        "    deployment_config=aciconfig,\n",
        ")\n",
        "\n",
        "service.wait_for_deployment(show_output=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# send raw HTTP request to test the web service.\n",
        "import requests\n",
        "\n",
        "# send a random row from the test set to score\n",
        "random_index = np.random.randint(0, len(X_test) - 1)\n",
        "input_data = '{\"data\": [' + str(list(X_test[random_index])) + \"]}\"\n",
        "\n",
        "headers = {\"Content-Type\": \"application/json\"}\n",
        "\n",
        "resp = requests.post(service.scoring_uri, input_data, headers=headers)\n",
        "\n",
        "print(\"POST to url\", service.scoring_uri)\n",
        "print(\"label:\", y_test[random_index])\n",
        "print(\"prediction:\", resp.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - Pytorch and Tensorflow",
      "language": "python",
      "name": "python38-azureml-pt-tf"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "9169f1d4e16acc976bbb73e323b0dbdf23f1c55e833fb2befffc4fb50ac2de2f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
